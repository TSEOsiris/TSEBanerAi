#!/usr/bin/env python3
"""
–ü–∞—Ä—Å–∏–Ω–≥ Travels in Calradia –∏–∑ extracted text –¥–ª—è fine-tuning
–ò–∑–≤–ª–µ–∫–∞–µ—Ç –≤—Å–µ –≥–ª–∞–≤—ã –∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç –¥–ª—è —Ç—é–Ω–∏–Ω–≥–∞
"""

import re
import json
import sys
from pathlib import Path
from typing import Dict, List, Any, Optional
from collections import defaultdict

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–æ–¥–∏—Ä–æ–≤–∫–∏ –¥–ª—è Windows
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')


class TravelsParser:
    """–ü–∞—Ä—Å–µ—Ä –¥–ª—è Travels in Calradia"""
    
    def __init__(self, input_file: Path, output_dir: Path):
        self.input_file = input_file
        self.output_dir = output_dir
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
    def parse_file(self) -> Dict[int, Dict[str, Any]]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —Ñ–∞–π–ª–∞ –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –≥–ª–∞–≤"""
        print(f"üìñ Reading file: {self.input_file}")
        
        with open(self.input_file, 'r', encoding='utf-8', errors='ignore') as f:
            lines = f.readlines()
        
        chapters: Dict[int, Dict[str, Any]] = defaultdict(lambda: {
            'chapter': 0,
            'title': None,
            'pages': {}
        })
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞
        start_pattern = r'<string\s+id="travels_in_calradia_chapter_(\d+)_(?:page_(\d+)|title)"\s+text="'
        end_pattern = r'"\s*/>'
        
        i = 0
        found_count = 0
        
        while i < len(lines):
            line = lines[i]
            
            # –ò—â–µ–º –Ω–∞—á–∞–ª–æ —Å—Ç—Ä–æ–∫–∏
            start_match = re.search(start_pattern, line, re.IGNORECASE)
            if start_match:
                chapter_num = int(start_match.group(1))
                page_num = start_match.group(2)
                
                chapters[chapter_num]['chapter'] = chapter_num
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –ø–æ—Å–ª–µ text="
                text_start = start_match.end()
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∑–∞–∫—Ä—ã–≤–∞—é—â–∞—è –∫–∞–≤—ã—á–∫–∞ –≤ —ç—Ç–æ–π –∂–µ —Å—Ç—Ä–æ–∫–µ
                if '" />' in line[text_start:]:
                    # –¢–µ–∫—Å—Ç –≤ –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–µ
                    text_end = line.find('" />', text_start)
                    text = line[text_start:text_end]
                else:
                    # –¢–µ–∫—Å—Ç —Ä–∞–∑–±–∏—Ç –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫ - —Å–æ–±–∏—Ä–∞–µ–º –¥–æ –∑–∞–∫—Ä—ã–≤–∞—é—â–µ–π –∫–∞–≤—ã—á–∫–∏
                    text_parts = [line[text_start:].rstrip()]
                    i += 1
                    
                    while i < len(lines):
                        next_line = lines[i]
                        if '" />' in next_line:
                            # –ù–∞—à–ª–∏ –∫–æ–Ω–µ—Ü
                            text_end = next_line.find('" />')
                            text_parts.append(next_line[:text_end])
                            break
                        else:
                            text_parts.append(next_line.rstrip())
                        i += 1
                    
                    text = ''.join(text_parts)
                
                # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç –æ—Ç —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤ –∏ –∑–∞–º–µ–Ω—è–µ–º {newline} –Ω–∞ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
                text = text.replace('\\"', '"').replace('\\n', '\n').replace('\\t', '\t')
                text = text.replace('{newline}', '\n')
                
                found_count += 1
                
                if page_num is None:
                    # –≠—Ç–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫ –≥–ª–∞–≤—ã
                    chapters[chapter_num]['title'] = text
                else:
                    # –≠—Ç–æ —Å—Ç—Ä–∞–Ω–∏—Ü–∞
                    page_num_int = int(page_num)
                    chapters[chapter_num]['pages'][page_num_int] = text
            
            i += 1
        
        print(f"‚úÖ Found {found_count} matches for {len(chapters)} chapters")
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å–ª–æ–≤–∞—Ä–∏ —Å—Ç—Ä–∞–Ω–∏—Ü –≤ —Å–ø–∏—Å–∫–∏
        for chapter_num in chapters:
            max_page = max(chapters[chapter_num]['pages'].keys()) if chapters[chapter_num]['pages'] else -1
            pages_list = []
            for p in range(max_page + 1):
                if p in chapters[chapter_num]['pages']:
                    pages_list.append(chapters[chapter_num]['pages'][p])
            chapters[chapter_num]['pages'] = pages_list
        
        return dict(sorted(chapters.items()))
    
    def save_chapters(self, chapters: Dict[int, Dict[str, Any]]):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≥–ª–∞–≤ –≤ JSON"""
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∂–¥—É—é –≥–ª–∞–≤—É –æ—Ç–¥–µ–ª—å–Ω–æ
        chapters_dir = self.output_dir / 'travels_calradia'
        chapters_dir.mkdir(parents=True, exist_ok=True)
        
        for chapter_num, chapter_data in chapters.items():
            chapter_file = chapters_dir / f'chapter_{chapter_num:02d}.json'
            with open(chapter_file, 'w', encoding='utf-8') as f:
                json.dump(chapter_data, f, ensure_ascii=False, indent=2)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—ã–π —Ñ–∞–π–ª
        full_file = self.output_dir / 'travels_calradia.json'
        chapters_list = [chapters[i] for i in sorted(chapters.keys())]
        with open(full_file, 'w', encoding='utf-8') as f:
            json.dump({
                'title': 'Travels in Calradia',
                'total_chapters': len(chapters),
                'chapters': chapters_list
            }, f, ensure_ascii=False, indent=2)
        
        print(f"‚úÖ Saved {len(chapters)} chapters to {chapters_dir}")
        print(f"‚úÖ Saved full file to {full_file.name}")
        
        return len(chapters)
    
    def create_finetuning_format(self, chapters: Dict[int, Dict[str, Any]]) -> List[Dict[str, Any]]:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ñ–æ—Ä–º–∞—Ç–∞ –¥–ª—è fine-tuning"""
        finetuning_data = []
        
        for chapter_num in sorted(chapters.keys()):
            chapter = chapters[chapter_num]
            
            # –°–æ–±–∏—Ä–∞–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç –≥–ª–∞–≤—ã
            full_text_parts = []
            if chapter.get('title'):
                full_text_parts.append(f"Chapter {chapter_num}: {chapter['title']}")
            
            for page_num, page_text in enumerate(chapter.get('pages', [])):
                if page_text and page_text.strip():
                    full_text_parts.append(page_text.strip())
            
            full_text = '\n\n'.join(full_text_parts)
            
            if full_text.strip():
                finetuning_data.append({
                    'id': f'travels_calradia_chapter_{chapter_num}',
                    'type': 'novella',
                    'source': 'digital_companion',
                    'chapter': chapter_num,
                    'title': chapter.get('title'),
                    'text': full_text,
                    'page_count': len(chapter.get('pages', []))
                })
        
        return finetuning_data
    
    def save_finetuning_format(self, finetuning_data: List[Dict[str, Any]]):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è fine-tuning"""
        output_file = self.output_dir / 'travels_calradia_finetuning.json'
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(finetuning_data, f, ensure_ascii=False, indent=2)
        
        print(f"‚úÖ Saved fine-tuning format to {output_file.name}")
        return len(finetuning_data)
    
    def parse(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –ø–∞—Ä—Å–∏–Ω–≥–∞"""
        print("=" * 60)
        print("PARSING TRAVELS IN CALRADIA")
        print("=" * 60)
        
        chapters = self.parse_file()
        
        if not chapters:
            print("‚ùå No chapters found!")
            return
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≥–ª–∞–≤—ã
        chapters_count = self.save_chapters(chapters)
        
        # –°–æ–∑–¥–∞–µ–º —Ñ–æ—Ä–º–∞—Ç –¥–ª—è fine-tuning
        finetuning_data = self.create_finetuning_format(chapters)
        finetuning_count = self.save_finetuning_format(finetuning_data)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        total_pages = sum(len(ch.get('pages', [])) for ch in chapters.values())
        total_text_length = sum(len(ch.get('text', '')) for ch in finetuning_data)
        
        print("\n" + "=" * 60)
        print("‚úÖ PARSING COMPLETED!")
        print("=" * 60)
        print(f"\nüìä Statistics:")
        print(f"   Chapters: {chapters_count}")
        print(f"   Total pages: {total_pages}")
        print(f"   Fine-tuning entries: {finetuning_count}")
        print(f"   Total text length: {total_text_length:,} characters")
        
        return {
            'chapters': chapters_count,
            'pages': total_pages,
            'entries': finetuning_count,
            'text_length': total_text_length
        }


def main():
    """Main entry point"""
    project_root = Path(__file__).parent.parent
    
    # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —Ñ–∞–π–ª —Å –ø–æ–ª–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º
    possible_files = [
        project_root / 'wiki_data' / 'travels_calradia' / '1.txt',
        project_root / 'wiki_data' / 'travels_calradia' / 'full_extracted_text.txt'
    ]
    
    input_file = None
    for f in possible_files:
        if f.exists():
            input_file = f
            break
    
    if not input_file:
        print(f"‚ùå File not found. Tried:")
        for f in possible_files:
            print(f"   {f}")
        return
    
    output_dir = project_root / 'finetuning_data'
    parser = TravelsParser(input_file, output_dir)
    parser.parse()


if __name__ == '__main__':
    main()

